查看cuda版本:cat /usr/local/cuda/version.txt
查看cudann版本:cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2

cuda_Event_t :cuda获得时间戳函数

cudaEventSynchronize:细粒度等待所有线程任务完成

Thrust开源库的简介是“code at speed of light”。光速代码的实现听上去太过夸张，但是thrust在cuda硬件加速中确实有着无比强大的功能。
Thrust是并行算法和数据结构的基于GPU CUDA的C++库。Thrust主要通过管理系统底层的功能比如memory access（内存获取）和memory allocation（内存分配）来实现加速，使得工程师们在GPU编程的环境下能更focus在算法的设计上。
Thrust的最主要特征是实现了几种数据结构和算法的高速并行计算（high performance heterogeneous parallel computing）。
例如sort，reduce，scan等。PS. 安装CUDA tooltik的时候会自动将thrust的头文件加入标准CUDA文件路径。因此应用thrust库并不需要额外安装手续。

Thrust提供了大量的函数类型集合，包括：转换(transformation)，规约(reduction)，前缀求和(prefix sum)，再排序(reordering)，排序(sorting)。
Thrust并不是传统意义上的函数库，因为它的所有内容都在所包含的头文件中。
因此，要避免包含所有的文件。只要包含需要的头文件就行了。

#include <thrust/host_vector.h>
#include <thrust/device_vector.h>:可以直接在GPU中创建对象,直接使用GPU
device_vector的创建一维数组的方式:
a. 	thrust::device_vector<double> *data[1];
   	data[0] = new thrust::device_vector<double> (n);//开辟大小是n的设备数组
b. 	thrust::device_vector<double> *data[1];
	double dataset[] = ...;
	data[0] = new thrust::device_vector<double>(dataset,dateset+p);//p是dataset的最大偏移量
device_vector创建二维数组data[5][10]的方式:
	thrust::device_vector<double> *data[5];//(只要这个数组大于1就行)
	for(int i = 0;i < 5;i++){
		data[i] = new thrust::device_vector<double>(10);
	}


Thrust官方使用介绍:https://docs.nvidia.com/cuda/thrust/
其他API用法
填充：thrust :: fill ( dev_ptr , dev_ptr + N, ( int ) 0);
获取设备指针：thrust :: device_ptr <int > dev_ptr = thrust :: device_malloc <int >(N); 	
		int * raw_ptr = thrust :: raw_pointer_cast ( dev_ptr ); 


获取本机可用的GPU个数:
	int count;
	cudaGetDeviceCount(&count);

绑定GPU，默认是0号GPU：这里的绑定不是说本程序必须要在哪个GPU上执行，而是说某一GPu可以运行该程序。
	int index = 1;
	cudaSetDevice(index);


Async类函数和非Async类函数的区别在于异步，是指定了流拷贝的。
一些计算能力为2.x或更高的设备可以将锁页内存到设备内存的数据传输和设备内存到锁页内存的数据传输并行执行。
应用程序可检查设备属性中的asyncEngineCount项来确定这一功能的支持程度，等于2时表示支持。
应用程序通过流来管理并行。一个流是一个顺次执行的命令序列。不同的流之间并行执行，没有固定的执行顺序。
流的创建与销毁：
	cudaStream_t stream[2];  
	for (int i = 0; i < 2; ++i)  
    		cudaStreamCreate(&stream[i]); 
	for (int i = 0; i < 2; ++i)  
    		cudaStreamDestroy(stream[i]);  
流的拷贝：
	cudaMemcpyAsync(inputDevPtr + i * size, hostPtr + i * size, size, cudaMemcpyHostToDevice, stream[i]);  
	cudaMemcpyAsync(hostPtr + i * size, outputDevPtr + i * size, size, cudaMemcpyDeviceToHost, stream[i]);
 




