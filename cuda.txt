查看cuda版本:cat /usr/local/cuda/version.txt
查看cudann版本:cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2

cuda_Event_t :cuda获得时间戳函数

cudaEventSynchronize:细粒度等待所有线程任务完成

Thrust开源库的简介是“code at speed of light”。光速代码的实现听上去太过夸张，但是thrust在cuda硬件加速中确实有着无比强大的功能。
Thrust是并行算法和数据结构的基于GPU CUDA的C++库。Thrust主要通过管理系统底层的功能比如memory access（内存获取）和memory allocation（内存分配）来实现加速，使得工程师们在GPU编程的环境下能更focus在算法的设计上。
Thrust的最主要特征是实现了几种数据结构和算法的高速并行计算（high performance heterogeneous parallel computing）。
例如sort，reduce，scan等。PS. 安装CUDA tooltik的时候会自动将thrust的头文件加入标准CUDA文件路径。因此应用thrust库并不需要额外安装手续。

Thrust提供了大量的函数类型集合，包括：转换(transformation)，规约(reduction)，前缀求和(prefix sum)，再排序(reordering)，排序(sorting)。
Thrust并不是传统意义上的函数库，因为它的所有内容都在所包含的头文件中。
因此，要避免包含所有的文件。只要包含需要的头文件就行了。Thrust官方使用介绍:https://docs.nvidia.com/cuda/thrust/
#include <thrust/host_vector.h>
#include <thrust/device_vector.h>:可以直接在GPU中创建对象,直接使用GPU
device_vector的创建一维数组的方式:
a. 	thrust::device_vector<double> *data[1];
   	data[0] = new thrust::device_vector<double> (n);//开辟大小是n的设备数组
b. 	thrust::device_vector<double> *data[1];
	double dataset[] = ...;
	data[0] = new thrust::device_vector<double>(dataset,dateset+p);//p是dataset的最大偏移量
device_vector创建二维数组data[5][10]的方式:
	thrust::device_vector<double> *data[5];//(只要这个数组大于1就行)
	for(int i = 0;i < 5;i++){
		data[i] = new thrust::device_vector<double>(10);
	}


其他API用法:
填充：thrust :: fill ( dev_ptr , dev_ptr + N, ( int ) 0);
获取设备指针：thrust :: device_ptr <int > dev_ptr = thrust :: device_malloc <int >(N); 	
		int * raw_ptr = thrust :: raw_pointer_cast ( dev_ptr ); 
排序:	int A[N] = {1, 4, 2, 8, 5, 7};
	thrust::sort(A, A + N);
	int    keys[N] = {  1,   4,   2,   8,   5,   7};
	char values[N] = {'a', 'b', 'c', 'd', 'e', 'f'};//也能对cpu排序
	thrust::sort_by_key(keys, keys + N, values);//默认由小到大
	thrust::stable_sort(A, A + N, thrust::greater<int>());//由大到小
加和: thrust::reduce_by_key == cub::DeviceReduce::ReduceByKey ;
CUB库的使用:https://nvlabs.github.io/cub/structcub_1_1_device_reduce.html

多个CUDA库共享的数据类型，定义在library_types.h头文件中
cublasHandle_t, 一个指针类型，指向一个不透明的结构可以c维持cuBLAS库环境，这个环境需要使用cublasCreate()进行初始化，返回的句柄也必须传为接下来的库函数的调用中，环境在结束时使用cublasDestroy()销毁
cublasStatust,一个函数状态的返回类型，cuBLAS库函数返回其状态，状态值有很多，常见的，CUBLAS_STATUS_SUCCESS, CUBLAS_STATUS_NOT_INIYIALIZED,edc.

获取本机可用的GPU个数:
	int count;
	cudaGetDeviceCount(&count);
获取本设备信息:
	int dev_num;
	cudaGetDevice(&dev_num);
设置下文设备:绑定GPU，默认是0号GPU：这里的绑定不是说本程序必须要在哪个GPU上执行，而是说某一GPu可以运行该程序
	int dev_num = 0;
	cudaSetDevice(dev_num);


Async类函数和非Async类函数的区别在于异步，是指定了流拷贝的。
一些计算能力为2.x或更高的设备可以将锁页内存到设备内存的数据传输和设备内存到锁页内存的数据传输并行执行。
应用程序可检查设备属性中的asyncEngineCount项来确定这一功能的支持程度，等于2时表示支持。
应用程序通过流来管理并行。一个流是一个顺次执行的命令序列。不同的流之间并行执行，没有固定的执行顺序。
流的创建与销毁：
	cudaStream_t stream[2];  
	for (int i = 0; i < 2; ++i)  
    		cudaStreamCreate(&stream[i]); 
	for (int i = 0; i < 2; ++i)  
    		cudaStreamDestroy(stream[i]);  
流的拷贝：
	cudaMemcpyAsync(inputDevPtr + i * size, hostPtr + i * size, size, cudaMemcpyHostToDevice, stream[i]);  
	cudaMemcpyAsync(hostPtr + i * size, outputDevPtr + i * size, size, cudaMemcpyDeviceToHost, stream[i]);
 

cudaDeviceSynchronize() 会阻塞当前程序的执行，直到所有任务都处理完毕（这里的任务其实就是指的是所有的线程都已经执行完了kernel function）
cudaThreadSynchronize()的功能和cudaDeviceSynchronize()基本上一样，这个函数在新版本的cuda中已经被“废弃”了，不推荐使用，如果程序中真的需要做同步操作，推荐使用cudaDeviceSynchronize()
cudaStreamSynchronize()和上面的两个函数类似，这个函数带有一个参数，cuda流ID，它只阻塞那些cuda流ID等于参数中指定ID的那些cuda例程，对于那些流ID不等的例程，还是异步执行的。

CUDA atomic原子操作:
a. atomicAdd族：
	int atomicAdd(int* address, int val);
	unsigned int atomicAdd(unsigned int* address,unsigned int val);
	unsigned long long int atomicAdd(unsigned long long int* address,unsigned long long int val);
b. atomicSub族：
	int atomicSub(int* address, int val);
	unsigned int atomicSub(unsigned int* address, unsigned int val
c. atomicExch族：读取位于全局或共享存储器中地址address 处的32 位或64 位字old，并将val 存储在存储器的同一地址中。这两项操作在一次原子事务中执行。该函数将返回old。只有全局存储器支持64 位字
	int atomicExch(int* address, int val);

	unsigned int atomicExch(unsigned int* address,unsigned int val);
	
unsigned long long int atomicExch(unsigned long long int* address,unsigned long long int val);

	float atomicExch(float* address, float val);
d. atomicMin族：读取位于全局或共享存储器中地址address 处的32 位字old，计算old 和val 的最小值，并将结果存储在存储器的同一地址中。这三项操作在一次原子事务中执行。该函数将返回old
	int atomicMin(int* address, int val);
	unsigned int atomicMin(unsigned int* address,unsigned int val);
e. atomicMax族：
	int atomicMax(int* address, int val);
	unsigned int atomicMax(unsigned int* address,unsigned int val);

f.还有不常用的atomic系列函数，见网址:https://blog.csdn.net/dcrmg/article/details/54959306

__device __forceline__ void func();//forceline自动内联这些设备的功能

__double_as__longlong诸如此类型 属于CUDA语法中的精度转换









